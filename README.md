# åŸºäºå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒä¸çœŸå®è§£å¼•å¯¼å¾®è°ƒçš„MCTSé›†æˆæ¡†æ¶

ä¸€ä¸ªèåˆäº†**å¯¹æ¯”å­¦ä¹ **ã€**MCTSæ ‘æœç´¢**å’Œ**ä¸‰å…ƒç»„æŸå¤±**çš„å…ˆè¿›ç¬¦å·å›å½’ç³»ç»Ÿï¼Œé€šè¿‡"é€šç”¨é¢„è®­ç»ƒ + ç²¾å‡†å¾®è°ƒ"çš„åŒé˜¶æ®µç­–ç•¥ï¼Œå®ç°ä»å¹¿æ³›æ•°å­¦çŸ¥è¯†å­¦ä¹ åˆ°ç‰¹å®šé—®é¢˜æ·±åº¦ä¼˜åŒ–çš„å®Œæ•´æµç¨‹ã€‚

## ğŸ¯ æ ¸å¿ƒæ€æƒ³

æœ¬æ¡†æ¶é€šè¿‡**"é€šç”¨é¢„è®­ç»ƒ + ç²¾å‡†å¾®è°ƒ"**çš„åŒé˜¶æ®µç­–ç•¥ï¼Œæ„å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿä»å¹¿æ³›çš„æ•°å­¦çŸ¥è¯†ä¸­å¯åŠ¨ï¼Œå¹¶èƒ½é’ˆå¯¹ç‰¹å®šé—®é¢˜è¿›è¡Œæ·±åº¦è‡ªæˆ‘ä¼˜åŒ–çš„ç¬¦å·å›å½’ç³»ç»Ÿã€‚

### ä¸‰å¤§æ ¸å¿ƒç»„ä»¶

1. **è¡¨è¾¾å¼ç¼–ç å™¨** $Encoder_{expr}$ **"ç†è®ºå»ºæ¨¡å®¶"**
   - å°†æ•°å­¦è¡¨è¾¾å¼çš„ç¬¦å·ç»“æ„æ˜ å°„åˆ°è¯­ä¹‰ä¸°å¯Œçš„åµŒå…¥ç©ºé—´
   - æ”¯æŒå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒå’ŒçœŸå®è§£å¼•å¯¼å¾®è°ƒ

2. **æ•°æ®ç¼–ç å™¨** $Encoder_{data}$ **"é¦–å¸­æ•°æ®å­¦å®¶"**
   - å°†æ•°æ®é›†çš„å†…åœ¨æ¨¡å¼ä¸ç‰¹å¾æ˜ å°„åˆ°ä¸è¡¨è¾¾å¼ç¼–ç å™¨ç›¸åŒçš„åµŒå…¥ç©ºé—´
   - ç¡®ä¿åµŒå…¥ç©ºé—´çš„ä¸€è‡´æ€§ä¸å¯¹é½æ€§

3. **MCTSå¼•æ“** - **"æ¢ç´¢è€…"**
   - åœ¨ç¼–ç å™¨å¡‘é€ çš„è¯­ä¹‰ç©ºé—´ä¸­é«˜æ•ˆæ¢ç´¢è¡¨è¾¾å¼ç»“æ„
   - ä½¿ç”¨å¤åˆå¥–åŠ±ï¼ˆç»“æ„å¼•å¯¼ + æ•°æ®å¯¹é½ + çœŸå®ç²¾åº¦ï¼‰å®ç°æ™ºèƒ½æ¢ç´¢

## ğŸ“‹ ç›®å½•ç»“æ„

```
symbolic-regression-mcts/
â”‚
â”œâ”€â”€ ğŸ“œ README.md                  # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ ğŸ“ pyproject.toml             # é¡¹ç›®å…ƒæ•°æ®ã€ä¾èµ–ã€é…ç½®
â”œâ”€â”€ âš™ï¸ config.yaml                # å®éªŒè¶…å‚æ•°é…ç½®
â”‚
â”œâ”€â”€ ğŸ“‚ data/                      # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ ğŸŒ pretrain/              # é¢„è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ ğŸš€ online_finetune/       # åœ¨çº¿å¾®è°ƒåŸºå‡†ä»»åŠ¡
â”‚   â””â”€â”€ ğŸ”¬ production/            # å®æˆ˜æ•°æ®
â”‚
â”œâ”€â”€ ğŸ“‚ src/                       # æ ¸å¿ƒæºä»£ç 
â”‚   â””â”€â”€ ğŸ“¦ symbolic_regression/   # PythonåŒ…
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ§  core/              # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ mcts_engine.py      # MCTSå¼•æ“
â”‚       â”‚   â””â”€â”€ ğŸ“„ reward_calculator.py # å¤åˆå¥–åŠ±è®¡ç®—
â”‚       â”œâ”€â”€ ğŸ–¼ï¸ models/            # ç¥ç»ç½‘ç»œæ¨¡å‹
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ expression_encoder.py # è¡¨è¾¾å¼ç¼–ç å™¨
â”‚       â”‚   â””â”€â”€ ğŸ“„ data_encoder.py      # æ•°æ®ç¼–ç å™¨
â”‚       â”œâ”€â”€ âš™ï¸ training/          # è®­ç»ƒæµç¨‹
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ pretrain_pipeline.py  # é¢„è®­ç»ƒæµç¨‹
â”‚       â”‚   â””â”€â”€ ğŸ“„ finetune_loop.py      # åœ¨çº¿å¾®è°ƒå¾ªç¯
â”‚       â””â”€â”€ ğŸ”§ utils/             # å·¥å…·å‡½æ•°
â”‚           â”œâ”€â”€ ğŸ“„ data_loader.py       # æ•°æ®åŠ è½½å™¨
â”‚           â””â”€â”€ ğŸ“„ expression_parser.py # è¡¨è¾¾å¼è§£æå™¨
â”‚
â”œâ”€â”€ âš—ï¸ scripts/                   # å¯æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ ğŸ“„ 0_run_pretraining.py   # é˜¶æ®µé›¶ï¼šé¢„è®­ç»ƒ
â”‚   â”œâ”€â”€ ğŸ“„ 1_run_online_loop.py   # é˜¶æ®µä¸€ï¼šåœ¨çº¿å¾®è°ƒ
â”‚   â”œâ”€â”€ ğŸ“„ 2_run_inference.py     # é˜¶æ®µäºŒï¼šæ¨ç†å®æˆ˜
â”‚   â””â”€â”€ ğŸ“„ generate_pretrain_data.py # æ•°æ®ç”Ÿæˆ
â”‚
â”œâ”€â”€ ğŸ“‚ models_weights/            # æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ ğŸ“ pretrained/            # é¢„è®­ç»ƒæƒé‡
â”‚   â””â”€â”€ ğŸ“ finetuned/             # å¾®è°ƒæƒé‡
â”‚
â”œâ”€â”€ ğŸ“‚ results/                   # å®éªŒç»“æœ
â”‚   â”œâ”€â”€ ğŸ“ logs/                  # è®­ç»ƒæ—¥å¿—
â”‚   â”œâ”€â”€ ğŸ“ plots/                 # å¯è§†åŒ–å›¾è¡¨
â”‚   â””â”€â”€ ğŸ“ metrics/               # æ€§èƒ½æŒ‡æ ‡
â”‚
â””â”€â”€ ğŸ§ª tests/                     # å•å…ƒæµ‹è¯•
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd symbolic-regression-mcts

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# æˆ–
.venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -e .
```

### é…ç½®æ–‡ä»¶

ç¼–è¾‘ `config.yaml` è°ƒæ•´å‚æ•°ï¼š

```yaml
# æ¨¡å‹é…ç½®
model:
  expression_encoder:
    embedding_dim: 512
    n_heads: 8
    n_layers: 6

  data_encoder:
    embedding_dim: 512
    n_heads: 8
    n_layers: 6

# MCTSé…ç½®
mcts:
  max_depth: 12
  max_iterations: 1000
  exploration_constant: 1.4

# è®­ç»ƒé…ç½®
training:
  pretrain:
    batch_size: 32
    learning_rate: 1e-4
    num_epochs: 100

  online_finetune:
    batch_size: 8
    learning_rate: 1e-6  # æä½å­¦ä¹ ç‡
    mcts_epochs: 50
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### é˜¶æ®µé›¶ï¼šåŸºäºå¯¹æ¯”å­¦ä¹ çš„é¢„è®­ç»ƒ

é¢„è®­ç»ƒé˜¶æ®µä½¿ç”¨å¯¹ç§°æ€§InfoNCEæŸå¤±å¯¹ä¸¤ä¸ªç¼–ç å™¨è¿›è¡Œè”åˆè®­ç»ƒï¼š

```bash
# ç”Ÿæˆé¢„è®­ç»ƒæ•°æ®
python scripts/generate_pretrain_data.py

# è¿è¡Œé¢„è®­ç»ƒ
python scripts/0_run_pretraining.py
```

**æ ¸å¿ƒæµç¨‹ï¼š**
1. ç”Ÿæˆæµ·é‡(è¡¨è¾¾å¼, æ•°æ®é›†)å¯¹ä½œä¸º"é€šè¯†æ•™æ"
2. ä½¿ç”¨å¯¹ç§°æ€§å¯¹æ¯”æŸå¤±ï¼ˆInfoNCE Lossï¼‰è®­ç»ƒä¸¤ä¸ªç¼–ç å™¨
3. å­¦ä¹ ç¬¦å·ä¸æ•°å€¼ä¹‹é—´çš„é€šç”¨å¯¹é½å…³ç³»

### é˜¶æ®µä¸€ï¼šåŸºäºçœŸå®è§£çš„ä¸“å®¶å¾®è°ƒ

å¾®è°ƒé˜¶æ®µä½¿ç”¨MCTS+ä¸‰å…ƒç»„æŸå¤±å¯¹ç¼–ç å™¨è¿›è¡Œç²¾ç»†æ‰“ç£¨ï¼š

```bash
# è¿è¡Œåœ¨çº¿å¾®è°ƒ
python scripts/1_run_online_loop.py
```

**æ ¸å¿ƒæµç¨‹ï¼š**
1. ä¸ºæ¯ä¸ªåŸºå‡†é—®é¢˜å¯åŠ¨MCTSæ¢ç´¢
2. å‘ç°"è²Œåˆç¥ç¦»"çš„éš¾è´Ÿæ ·æœ¬ï¼ˆç»“æ„ç›¸ä¼¼ä½†æ•ˆæœå·®ï¼‰
3. ä½¿ç”¨ä¸‰å…ƒç»„æŸå¤±æ¨éš¾è´Ÿæ ·æœ¬ã€æ‹‰è¿‘çœŸå®è§£ä¸æ•°æ®å¯¹é½
4. æä½å­¦ä¹ ç‡è¿›è¡Œç²¾å‡†æ ¡å‡†

**å¥–åŠ±å‡½æ•°ï¼š**
```
r = w1 * R_acc + w2 * R_align - w3 * R_complex
```
- `R_acc`: çœŸå®ç²¾åº¦å¥–åŠ±
- `R_align`: è¯­ä¹‰å¯¹é½å¥–åŠ±
- `R_complex`: å¤æ‚åº¦æƒ©ç½š

### é˜¶æ®µäºŒï¼šåœ¨çº¿æ¨ç†ä¸æ±‚è§£

æ¨ç†é˜¶æ®µä½¿ç”¨å†»ç»“ç¼–ç å™¨è¿›è¡Œå®æˆ˜ï¼š

```bash
# è¿è¡Œæ¨ç†
python scripts/2_run_inference.py
```

**æ ¸å¿ƒæµç¨‹ï¼š**
1. åŠ è½½æœ€ç»ˆçš„ä¸“å®¶æƒé‡ï¼ˆå†»ç»“ç¼–ç å™¨ï¼‰
2. ä¸€æ¬¡æ€§è®¡ç®—ä»»åŠ¡æ•°æ®åµŒå…¥ä½œä¸º"ç›®æ ‡ç¯å¡”"
3. ä½¿ç”¨å¤åˆå¥–åŠ±è¿›è¡ŒMCTSæ¢ç´¢
4. æå–æœ€ä½³è¡¨è¾¾å¼ä½œä¸ºæœ€ç»ˆè§£

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆé¢„è®­ç»ƒé˜¶æ®µï¼‰

ä½¿ç”¨å¯¹ç§°æ€§InfoNCE Lossï¼š

```python
# è¡¨è¾¾å¼->æ•°æ®çš„å¯¹æ¯”æŸå¤±
loss_expr_to_data = InfoNCE(similarity_matrix, labels)

# æ•°æ®->è¡¨è¾¾å¼çš„å¯¹æ¯”æŸå¤±
loss_data_to_expr = InfoNCE(similarity_matrix.transpose(), labels)

# å¯¹ç§°æ€§æŸå¤±
contrastive_loss = 0.5 * (loss_expr_to_data + loss_data_to_expr)
```

### ä¸‰å…ƒç»„æŸå¤±ï¼ˆå¾®è°ƒé˜¶æ®µï¼‰

```python
# ä¸‰å…ƒç»„æŸå¤±ï¼šæ¨è¿œéš¾è´Ÿæ ·æœ¬
triplet_loss = TripletMarginLoss(
    anchor=true_expr,
    positive=true_expr,  # è‡ªå·±
    negative=hard_negative,
    margin=1.0
)

# å¯¹é½æŸå¤±ï¼šæ‹‰è¿‘çœŸå®è§£ä¸æ•°æ®
alignment_loss = 1 - cosine_similarity(true_expr_embedding, data_embedding)

# æ€»æŸå¤±
total_loss = triplet_loss + Î» * alignment_loss
```

### MCTSæœç´¢ç­–ç•¥

1. **é€‰æ‹©ï¼ˆSelectionï¼‰**ï¼šä½¿ç”¨UCBé€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹
2. **æ‰©å±•ï¼ˆExpansionï¼‰**ï¼šåŸºäºæ¨¡æ¿ç”Ÿæˆå€™é€‰è¡¨è¾¾å¼
3. **æ¨¡æ‹Ÿï¼ˆSimulationï¼‰**ï¼šè¯„ä¼°å¤åˆå¥–åŠ±
4. **åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰**ï¼šæ›´æ–°è·¯å¾„ä»·å€¼

## ğŸ“Š æ€§èƒ½ç‰¹ç‚¹

- **é€šç”¨æ€§**ï¼šé¢„è®­ç»ƒé˜¶æ®µå­¦ä¹ å¹¿æ³›æ•°å­¦çŸ¥è¯†
- **ç²¾å‡†æ€§**ï¼šå¾®è°ƒé˜¶æ®µé’ˆå¯¹ç‰¹å®šé—®é¢˜ä¼˜åŒ–
- **é«˜æ•ˆæ€§**ï¼šMCTSåœ¨è¯­ä¹‰ç©ºé—´ä¸­çš„æ™ºèƒ½æ¢ç´¢
- **å¯è§£é‡Šæ€§**ï¼šå¤åˆå¥–åŠ±æä¾›å¤šç»´åº¦è¯„ä¼°

## ğŸ› ï¸ è‡ªå®šä¹‰é…ç½®

### è°ƒæ•´æ¨¡å‹ç»“æ„

```yaml
model:
  expression_encoder:
    embedding_dim: 512  # åµŒå…¥ç»´åº¦
    n_heads: 8         # æ³¨æ„åŠ›å¤´æ•°
    n_layers: 6        # Transformerå±‚æ•°
```

### è°ƒæ•´MCTSå‚æ•°

```yaml
mcts:
  max_depth: 12              # æœ€å¤§æœç´¢æ·±åº¦
  max_iterations: 1000       # æœ€å¤§è¿­ä»£æ¬¡æ•°
  exploration_constant: 1.4  # æ¢ç´¢å¸¸æ•°
  simulation_count: 10       # æ¨¡æ‹Ÿæ¬¡æ•°
```

### è°ƒæ•´è®­ç»ƒå‚æ•°

```yaml
training:
  online_finetune:
    learning_rate: 1e-6      # å¾®è°ƒå­¦ä¹ ç‡ï¼ˆæä½ï¼‰
    mcts_epochs: 50          # MCTSå¾®è°ƒè½®æ•°
    triplet_margin: 1.0      # ä¸‰å…ƒç»„æŸå¤±è¾¹ç•Œ
    alignment_loss_weight: 0.5  # å¯¹é½æŸå¤±æƒé‡
```

## ğŸ“ˆ ç»“æœåˆ†æ

è®­ç»ƒå®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ï¼š

- **æ¨¡å‹æƒé‡**ï¼š`models_weights/finetuned/`
- **è®­ç»ƒæ—¥å¿—**ï¼š`results/logs/`
- **è®­ç»ƒå†å²**ï¼š`results/training_history.json`

### æŸ¥çœ‹è®­ç»ƒè¿›åº¦

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f results/logs/finetune.log

# æŸ¥çœ‹TensorBoardï¼ˆå¦‚æœå¯ç”¨ï¼‰
tensorboard --logdir results/logs/tensorboard/
```

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_mcts_engine.py -v
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
- Transformers åº“
- Scikit-learn æœºå™¨å­¦ä¹ åº“

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·åˆ›å»º Issue æˆ–è”ç³»ç»´æŠ¤è€…ã€‚

---

**å¼€å‘å›¢é˜Ÿ**ï¼šiFlow CLI
